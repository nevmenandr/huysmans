{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6837380-0507-40b1-b4d6-0f5ab14dad52",
   "metadata": {},
   "source": [
    "Проведем подробные тесты для тех моделей, которые показали хорошую точность на предварительных тестах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465cb5f4-c023-41e2-9cf4-5e67ab20014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f9bf1d-9b8f-4f20-a19d-4ac795fbbcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>prudentius</td>\n",
       "      <td>prud.psycho</td>\n",
       "      <td>praefatio senex fidelis primus credo uia abram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius3</td>\n",
       "      <td>epistula sidonius auitus salus multus uinculum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius2</td>\n",
       "      <td>epistula sidonius ecdicio salus duo nunc parit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius1</td>\n",
       "      <td>epistula sidonius constantio salus praecipio d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius5</td>\n",
       "      <td>epistula sidonius petronius salus audio lectit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann15</td>\n",
       "      <td>interea rex parthi uologaeses cognosco corbulo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann11</td>\n",
       "      <td>ualerium asiaticum bis consul quondam adulter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann12</td>\n",
       "      <td>caedes messalinae convulsus princeps domus ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann13</td>\n",
       "      <td>primus nouus principatus mors iunii silanus pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0</td>\n",
       "      <td>ammianus</td>\n",
       "      <td>ammianus_res_gestae</td>\n",
       "      <td>liber caput gallus caesar saeuitia emetior ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>898 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target      author                title  \\\n",
       "0         1  prudentius          prud.psycho   \n",
       "1         1    sidonius            sidonius3   \n",
       "2         1    sidonius            sidonius2   \n",
       "3         1    sidonius            sidonius1   \n",
       "4         1    sidonius            sidonius5   \n",
       "..      ...         ...                  ...   \n",
       "893       0     tacitus            tac.ann15   \n",
       "894       0     tacitus            tac.ann11   \n",
       "895       0     tacitus            tac.ann12   \n",
       "896       0     tacitus            tac.ann13   \n",
       "897       0    ammianus  ammianus_res_gestae   \n",
       "\n",
       "                                                  text  \n",
       "0    praefatio senex fidelis primus credo uia abram...  \n",
       "1    epistula sidonius auitus salus multus uinculum...  \n",
       "2    epistula sidonius ecdicio salus duo nunc parit...  \n",
       "3    epistula sidonius constantio salus praecipio d...  \n",
       "4    epistula sidonius petronius salus audio lectit...  \n",
       "..                                                 ...  \n",
       "893  interea rex parthi uologaeses cognosco corbulo...  \n",
       "894  ualerium asiaticum bis consul quondam adulter ...  \n",
       "895  caedes messalinae convulsus princeps domus ori...  \n",
       "896  primus nouus principatus mors iunii silanus pr...  \n",
       "897  liber caput gallus caesar saeuitia emetior ins...  \n",
       "\n",
       "[898 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "base_dir = 'corpus_preprocessed'\n",
    "\n",
    "for target in ['aimait', 'terribles']:\n",
    "    target_label = 1 if target == 'aimait' else 0\n",
    "    \n",
    "    target_dir = os.path.join(base_dir, target)\n",
    "    \n",
    "    for author in os.listdir(target_dir):\n",
    "        author_dir = os.path.join(target_dir, author)\n",
    "        \n",
    "        if os.path.isdir(author_dir):\n",
    "            for filename in os.listdir(author_dir):\n",
    "                if filename.endswith('.txt'):\n",
    "                    file_path = os.path.join(author_dir, filename)\n",
    "                    \n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        text = file.read()\n",
    "                    data.append({\n",
    "                        'target': target_label,\n",
    "                        'author': author,\n",
    "                        'title': filename[:-4],\n",
    "                        'text': text\n",
    "                    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fb1b148-ec61-47e4-b83d-b3c923d90877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import statistics\n",
    "\n",
    "def fit_compute(vocab, ngram, model, test_list, df):\n",
    "\n",
    "    less = min(df.target.value_counts())\n",
    "    balanced_df = pd.concat((df[df['target'] == 0].sample(less, random_state=7), df[df['target'] != 0].sample(less, random_state=7)))\n",
    "    \n",
    "    tfidf = TfidfVectorizer(max_features=vocab, ngram_range=(1, ngram))\n",
    "    tfidf.fit(balanced_df['text'])\n",
    "    \n",
    "    accs = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    f1 = []\n",
    "    \n",
    "    for author in test_list:\n",
    "        \n",
    "        train_df = df[df['author'] != author]\n",
    "        test_df = df[df['author'] == author]\n",
    "        \n",
    "        less = min(train_df.target.value_counts())\n",
    "        balanced_df = pd.concat((train_df[train_df['target'] == 0].sample(less, random_state=9), train_df[train_df['target'] != 0].sample(less, random_state=9)))\n",
    "\n",
    "        X_train = tfidf.transform(balanced_df['text']).toarray()\n",
    "        y_train = np.asarray(balanced_df['target'])\n",
    "        \n",
    "        X_test = tfidf.transform(test_df['text']).toarray()  \n",
    "        y_test = np.asarray(test_df['target'])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pre = model.predict(X_test)\n",
    "        \n",
    "        accs.append(accuracy_score(y_test,y_pre))\n",
    "        prec.append(precision_score(y_test,y_pre, zero_division=1.0))\n",
    "        rec.append(recall_score(y_test,y_pre, zero_division=1.0))\n",
    "        f1.append(f1_score(y_test,y_pre, zero_division=1.0))\n",
    "    \n",
    "    return statistics.fmean(accs), statistics.fmean(prec), statistics.fmean(rec), statistics.fmean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dde160-09ee-4243-85f9-529cae659353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prudentius',\n",
       " 'sidonius',\n",
       " 'gregorytours',\n",
       " 'ermoldus',\n",
       " 'tertullianus',\n",
       " 'vitae',\n",
       " 'rutulius',\n",
       " 'orientus',\n",
       " 'bonifatius',\n",
       " 'commodianus',\n",
       " 'regino',\n",
       " 'paulinus',\n",
       " 'apuleius',\n",
       " 'venantius',\n",
       " 'claudian',\n",
       " 'aldhelmus',\n",
       " 'floridus',\n",
       " 'tatuinus',\n",
       " 'strabo',\n",
       " 'ausonius',\n",
       " 'sedulius',\n",
       " 'iordanes',\n",
       " 'flavius_merobaudes',\n",
       " 'boethius',\n",
       " 'eusebius',\n",
       " 'pauldeacon',\n",
       " 'vita_cuthberti',\n",
       " 'fredegarus',\n",
       " 'freculphus',\n",
       " 'macer_floridus',\n",
       " 'abbo',\n",
       " 'petronius',\n",
       " 'terentius',\n",
       " 'symmachus',\n",
       " 'victor',\n",
       " 'martial',\n",
       " 'lactantius',\n",
       " 'cyprianus',\n",
       " 'plinius',\n",
       " 'sallustius',\n",
       " 'quintilian',\n",
       " 'caesar',\n",
       " 'propertius',\n",
       " 'suetonius',\n",
       " 'tibullus',\n",
       " 'fronto',\n",
       " 'statius',\n",
       " 'minucius',\n",
       " 'persius',\n",
       " 'ovid',\n",
       " 'juvenal',\n",
       " 'horace',\n",
       " 'vergil',\n",
       " 'livy',\n",
       " 'arnobius',\n",
       " 'gellius',\n",
       " 'alcuin',\n",
       " 'macrobius',\n",
       " 'catullus',\n",
       " 'plautus',\n",
       " 'sen',\n",
       " 'cicero',\n",
       " 'eginhardus',\n",
       " 'ambrosius',\n",
       " 'tacitus',\n",
       " 'ammianus']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_list = list(df['author'].unique())\n",
    "authors_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30750b80-c133-4eb3-858e-2db9b4380727",
   "metadata": {},
   "source": [
    "Будем проверять модели в порядке убывания наилучшего результата, достигнутого на предварительных тестах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcd6559e-b794-4fc3-8f44-a00fedbedb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost - logreg\n",
      "\n",
      "1000\t4\t0.7234304971584363\t0.6363636363636364\t0.9054533429533429\t0.5567733276824186\n",
      "50000\t4\t0.7862173599628184\t0.7575757575757576\t0.8988275613275614\t0.6700545142221432\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost - logreg\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = AdaBoostClassifier(estimator=LogisticRegression(), n_estimators=100, algorithm='SAMME', random_state=11)\n",
    "print('AdaBoost - logreg\\n')\n",
    "\n",
    "for vocab, n in [(1000, 4), (50000, 4)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dfc40c0-427b-455b-98b1-174f2614530d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost - logreg\n",
      "\n",
      "20000\t1\t0.7275769596212326\t0.7121212121212122\t0.8687469937469938\t0.592362621429607\n",
      "30000\t1\t0.7251566346243781\t0.696969696969697\t0.8789381914381914\t0.5912438885166158\n",
      "50000\t1\t0.7421506390287522\t0.7121212121212122\t0.8903318903318903\t0.6131876500750019\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost - logreg\n",
    "model = AdaBoostClassifier(estimator=LogisticRegression(), n_estimators=100, algorithm='SAMME', random_state=11)\n",
    "print('AdaBoost - logreg\\n')\n",
    "\n",
    "for vocab, n in [(20000, 1), (30000, 1), (50000, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c040b62-4c47-4100-b9a0-6ec70262cd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost - NB\n",
      "\n",
      "30000\t1\t0.800991590250709\t0.696969696969697\t0.96257215007215\t0.6663237951361118\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(estimator=BernoulliNB(), n_estimators=100, algorithm='SAMME', random_state=11)\n",
    "print('AdaBoost - NB\\n')\n",
    "\n",
    "for vocab, n in [(30000, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8719aa3-572d-4a6b-a217-325703ef5ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "\n",
      "100000\t4\t0.6457148515972045\t0.8484848484848485\t0.7368326118326118\t0.5895669986579077\n",
      "100000\t1\t0.6285956647411756\t0.803030303030303\t0.7566137566137566\t0.5661036199313711\n",
      "50000\t4\t0.6113244805361876\t0.7272727272727273\t0.7580868205868205\t0.4935045888683902\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli NB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "model = BernoulliNB()\n",
    "print('Bernoulli NB\\n')\n",
    "\n",
    "for vocab, n in [(100000, 4), (100000, 1), (50000, 4)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6636d78b-15cb-4280-adca-e02d3f93e649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "\n",
      "30000\t1\t0.6073776446291561\t0.696969696969697\t0.7881433381433381\t0.49594708167133184\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "print('Bernoulli NB\\n')\n",
    "\n",
    "for vocab, n in [(30000, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16dac9c7-df91-4261-a70d-bb65bab325c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN, RFC -> XGB\n",
      "\n",
      "100\t1\t0.7234495753660781\t0.6363636363636364\t0.9111050986050986\t0.5629895950751566\n",
      "500\t1\t0.7177410045063947\t0.6212121212121212\t0.9004810004810004\t0.5371830057236755\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "estimators=[('knn', KNeighborsClassifier(n_neighbors=3, metric='cosine')), \n",
    "             ('rfc', RandomForestClassifier())]\n",
    "\n",
    "model = StackingClassifier(estimators=estimators, final_estimator=XGBClassifier(n_estimators=100, max_depth=3))\n",
    "print(\"KNN, RFC -> XGB\\n\")\n",
    "\n",
    "for vocab, n in [(100, 1), (500, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e289b7b9-65da-4ba2-b329-54986b602c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN, RFC -> SVM\n",
      "\n",
      "500\t1\t0.7354138198803647\t0.6666666666666666\t0.9007635882635883\t0.5815850815850816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = StackingClassifier(estimators=estimators, final_estimator=SVC())\n",
    "print(\"KNN, RFC -> SVM\\n\")\n",
    "\n",
    "for vocab, n in [(500, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3a4c7cf-9655-4453-8f0b-b576bedf672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN, RFC -> logreg\n",
      "\n",
      "500\t1\t0.7411178878033798\t0.696969696969697\t0.8816137566137566\t0.5921789321789321\n"
     ]
    }
   ],
   "source": [
    "model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "print(\"KNN, RFC -> logreg\\n\")\n",
    "\n",
    "for vocab, n in [(500, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0710947-67b5-4707-9544-aba58c453760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "\n",
      "10000\t1\t0.7432111402607834\t0.7121212121212122\t0.8959235209235209\t0.621048834206729\n",
      "10000\t2\t0.7420824764695809\t0.7121212121212122\t0.8942400192400193\t0.6189827185042496\n",
      "100000\t1\t0.7322128164415196\t0.696969696969697\t0.8917147667147667\t0.6018110013325324\n",
      "100000\t2\t0.72687300535302\t0.696969696969697\t0.8893999518999518\t0.5988143988143989\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "print('SVM\\n')\n",
    "\n",
    "for vocab, n in [(10000, 1), (10000, 2), (100000, 1), (100000, 2)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "390d3af7-19b7-459a-9660-e90f236a3dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC\n",
      "\n",
      "100\t4\t0.7715759599416657\t0.6515151515151515\t0.9203944203944204\t0.585188246097337\n",
      "50\t3\t0.7205302845633367\t0.6212121212121212\t0.9117664742664743\t0.5456643165734075\n",
      "100\t2\t0.7695230731198325\t0.6666666666666666\t0.9177489177489178\t0.5987144168962351\n",
      "500\t4\t0.762749032029271\t0.696969696969697\t0.9240921115921116\t0.6347430103295206\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "print('RFC\\n')\n",
    "\n",
    "for vocab, n in [(100, 4), (50, 3), (100, 2), (500, 4)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5baf1e5-36d1-46a0-8bd5-79b95c8f5cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "\n",
      "1000\t1\t0.6959448738067538\t0.6666666666666666\t0.8478835978835979\t0.523241909605546\n",
      "1000\t2\t0.6917702224554254\t0.6666666666666666\t0.8472522847522848\t0.5229195369427477\n",
      "100\t1\t0.6831755475207035\t0.696969696969697\t0.8581830206830207\t0.5687547775769008\n",
      "100\t2\t0.6831755475207035\t0.696969696969697\t0.8581830206830207\t0.5687547775769008\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3, metric='cosine')\n",
    "print('KNN\\n')\n",
    "\n",
    "for vocab, n in [(1000, 1), (1000, 2), (100, 1), (100, 2)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94819248-e3ca-4037-9253-f37597965a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg\n",
      "\n",
      "100000\t1\t0.7149560572165581\t0.696969696969697\t0.8921356421356421\t0.5989111898202807\n",
      "50000\t1\t0.7185509702252879\t0.696969696969697\t0.8938191438191438\t0.6019414928505837\n",
      "30000\t1\t0.723101650647231\t0.696969696969697\t0.8980278980278981\t0.6057982421618785\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "print(\"logreg\\n\")\n",
    "\n",
    "for vocab, n in [(100000, 1), (50000, 1), (30000, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69c08d4f-9ba1-4f07-8750-dcdb7315fee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge, alpha = 1\n",
      "1000\t1\t0.7498689313755034\t0.6818181818181818\t0.908519721019721\t0.6032450691541601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "model = RidgeClassifier(alpha=1)\n",
    "print(\"Ridge, alpha = 1\")\n",
    "\n",
    "for vocab, n in [(1000, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30ca0d4b-56a5-4fef-bb10-790a426aaf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge, alpha = 5\n",
      "10000\t1\t0.7228608262776692\t0.696969696969697\t0.8980278980278981\t0.6057982421618785\n"
     ]
    }
   ],
   "source": [
    "model = RidgeClassifier(alpha=5)\n",
    "print(\"Ridge, alpha = 5\")\n",
    "\n",
    "for vocab, n in [(10000, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eac31c50-e69a-4eee-9835-7ff377a680ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[('svm', SVC(probability=True)), \n",
    "             ('nb', BernoulliNB()), \n",
    "             ('log', LogisticRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb378ddc-8a06-48d0-96b0-43ab9b9798ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t1\t0.7481699592399489\t0.6818181818181818\t0.9076779701779701\t0.6025702537734624\n",
      "10000\t1\t0.7468806126111851\t0.7121212121212122\t0.8980880230880232\t0.624712403838678\n",
      "20000\t1\t0.749497682523304\t0.6818181818181818\t0.9040103415103414\t0.5960164122219458\n",
      "30000\t1\t0.7657894485810887\t0.696969696969697\t0.9222582972582973\t0.6310056392228225\n"
     ]
    }
   ],
   "source": [
    "model = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier())\n",
    "\n",
    "for vocab, n in [(1000, 1), (10000, 1), (20000, 1), (30000, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4705476-26c7-461d-b800-b20a679fbd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\t1\t0.7334160904849162\t0.696969696969697\t0.89496151996152\t0.6050888389977218\n",
      "20000\t1\t0.7523149389557376\t0.7121212121212122\t0.8984487734487735\t0.6227017267687124\n",
      "30000\t1\t0.7322131376418318\t0.7121212121212122\t0.8976070226070226\t0.621816248610507\n"
     ]
    }
   ],
   "source": [
    "model = StackingClassifier(estimators=estimators, final_estimator=SVC())\n",
    "\n",
    "for vocab, n in [(10000, 1), (20000, 1), (30000, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "396cfd45-d94b-4b03-befc-091670684860",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[('svm', SVC(probability=True)), \n",
    "             ('log', LogisticRegression()),\n",
    "             ('rid', RidgeClassifier(alpha=5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36ad4f4b-1de7-4770-8e5c-ad5618476109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\t1\t0.7706649630667408\t0.696969696969697\t0.9138407888407888\t0.6232127897797755\n",
      "30000\t1\t0.7541644586961304\t0.6818181818181818\t0.9104737854737854\t0.6056957218674506\n"
     ]
    }
   ],
   "source": [
    "model = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier())\n",
    "\n",
    "for vocab, n in [(20000, 1), (30000, 1)]:\n",
    "    acc, prec, rec, f1 = fit_compute(vocab, n, model, authors_list, df)\n",
    "    print(f\"{vocab}\\t{n}\\t{acc}\\t{prec}\\t{rec}\\t{f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b70ad82-a65f-455f-94fe-328b8b913c24",
   "metadata": {},
   "source": [
    "нилучшие значения точности у следующих классификаторов:   \n",
    "1) AdaBoost с BernoulliNB (30000, 1) : 0.801   \n",
    "2) AdaBoost c LogisticRegression (50000, 4) : 0.786   \n",
    "3) RandomForest (100, 4) : 0.772   \n",
    "4) SVM, LogReg, Ridge -> RandomForest (20000, 1) : 0.771   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df715e8-1223-475c-b605-7e030411b26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6daa298c-27c6-46c8-b16e-e5fed7e6bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# :(\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "269c51b8-8ec9-45e0-96ea-59e0598cd2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "base_dir = 'corpus_preprocessed'\n",
    "\n",
    "for target in ['aimait', 'terribles']:\n",
    "    target_label = 1 if target == 'aimait' else 0\n",
    "    \n",
    "    target_dir = os.path.join(base_dir, target)\n",
    "    \n",
    "    for author in os.listdir(target_dir):\n",
    "        author_dir = os.path.join(target_dir, author)\n",
    "        \n",
    "        if os.path.isdir(author_dir):\n",
    "            for filename in os.listdir(author_dir):\n",
    "                if filename.endswith('.txt'):\n",
    "                    file_path = os.path.join(author_dir, filename)\n",
    "                    \n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        text = file.read()\n",
    "                    ctr[target_label] += Counter(text.split())\n",
    "                    data.append({\n",
    "                        'target': target_label,\n",
    "                        'author': author,\n",
    "                        'title': filename[:-4],\n",
    "                        'text': text\n",
    "                    })\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1a6f21-b2b7-4aba-9a9d-27262058feca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>prudentius</td>\n",
       "      <td>prud.psycho</td>\n",
       "      <td>praefatio senex fidelis primus credo uia abram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius3</td>\n",
       "      <td>epistula sidonius auitus salus multus uinculum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius2</td>\n",
       "      <td>epistula sidonius ecdicio salus duo nunc parit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius1</td>\n",
       "      <td>epistula sidonius constantio salus praecipio d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius5</td>\n",
       "      <td>epistula sidonius petronius salus audio lectit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann15</td>\n",
       "      <td>interea rex parthi uologaeses cognosco corbulo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann11</td>\n",
       "      <td>ualerium asiaticum bis consul quondam adulter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann12</td>\n",
       "      <td>caedes messalinae convulsus princeps domus ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann13</td>\n",
       "      <td>primus nouus principatus mors iunii silanus pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0</td>\n",
       "      <td>ammianus</td>\n",
       "      <td>ammianus_res_gestae</td>\n",
       "      <td>liber caput gallus caesar saeuitia emetior ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>898 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target      author                title  \\\n",
       "0         1  prudentius          prud.psycho   \n",
       "1         1    sidonius            sidonius3   \n",
       "2         1    sidonius            sidonius2   \n",
       "3         1    sidonius            sidonius1   \n",
       "4         1    sidonius            sidonius5   \n",
       "..      ...         ...                  ...   \n",
       "893       0     tacitus            tac.ann15   \n",
       "894       0     tacitus            tac.ann11   \n",
       "895       0     tacitus            tac.ann12   \n",
       "896       0     tacitus            tac.ann13   \n",
       "897       0    ammianus  ammianus_res_gestae   \n",
       "\n",
       "                                                  text  \n",
       "0    praefatio senex fidelis primus credo uia abram...  \n",
       "1    epistula sidonius auitus salus multus uinculum...  \n",
       "2    epistula sidonius ecdicio salus duo nunc parit...  \n",
       "3    epistula sidonius constantio salus praecipio d...  \n",
       "4    epistula sidonius petronius salus audio lectit...  \n",
       "..                                                 ...  \n",
       "893  interea rex parthi uologaeses cognosco corbulo...  \n",
       "894  ualerium asiaticum bis consul quondam adulter ...  \n",
       "895  caedes messalinae convulsus princeps domus ori...  \n",
       "896  primus nouus principatus mors iunii silanus pr...  \n",
       "897  liber caput gallus caesar saeuitia emetior ins...  \n",
       "\n",
       "[898 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23dfaa19-1ba8-450a-84c0-04d4f87d1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import statistics\n",
    "\n",
    "def compute_accuracy(tfidf, model, test_df):\n",
    "    authors = test_df['author'].unique()\n",
    "    accs = []\n",
    "    for author in authors:\n",
    "        df_temp = test_df[test_df['author'] == author]\n",
    "        X_test = tfidf.transform(df_temp['text']).toarray()\n",
    "        y_test = np.asarray(df_temp['target'])\n",
    "        y_pre = model.predict(X_test)\n",
    "        accs.append(accuracy_score(y_test,y_pre))\n",
    "\n",
    "    return statistics.fmean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b80e01c-ef09-4f06-aaf3-c8d65c07d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dim = [500, 1000, 5000, 10000, 20000, 30000, 50000, 100000]\n",
    "ngram = [1, 2, 3, 4]\n",
    "models = [] # logreg, bernoulli NB, SVM, random forest, stacking (from process), extra trees, KNN Bonus: neural networkss (LSTM) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db845d78-c747-4b05-a7f7-c4c56ef11126",
   "metadata": {},
   "source": [
    "Принцип оценки качества моделей: выбираем случайно несколько авторов. Для каждого автора тренируем модель на всех остальных авторах, применяем модель на текстах выбранного автора, считаем среднее арифметическое по accuracy. итоговая accuracy это среднее по всем выбранным авторам.\n",
    "\n",
    "Для чистоты эксперимента выберем авторов для валидации заранее, одних и тех же для всех моделей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57903ff-f649-454a-98ec-0c6bb0e0cd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - target: 34\n",
      "1 - target: 32\n"
     ]
    }
   ],
   "source": [
    "authors_class_0 = df[df['target'] == 0]['author'].unique()\n",
    "authors_class_1 = df[df['target'] == 1]['author'].unique()\n",
    "\n",
    "print(f\"0 - target: {len(authors_class_0)}\")\n",
    "print(f\"1 - target: {len(authors_class_1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed66ae2-2de9-4d0f-ba12-4245e7d656f4",
   "metadata": {},
   "source": [
    "Выберем по 6 авторов для валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a432dbbf-78e4-4fa4-b461-81804b0e4a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - target: ['tacitus', 'ambrosius', 'horace', 'cyprianus', 'eginhardus', 'martial']\n",
      "1 - target: ['sedulius', 'petronius', 'eusebius', 'boethius', 'bonifatius', 'vitae']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "selected_authors_0 = random.sample(list(authors_class_0), 6)\n",
    "selected_authors_1 = random.sample(list(authors_class_1), 6)\n",
    "\n",
    "print(\"0 - target:\", selected_authors_0)\n",
    "print(\"1 - target:\", selected_authors_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "183006db-48ae-4b7b-a6ef-03fb627af893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of 0 - target val texts: 109\n",
      "number of 1 - target val texts: 31\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of 0 - target val texts: {df[df['author'].isin(selected_authors_0)].shape[0]}\")\n",
    "print(f\"number of 1 - target val texts: {df[df['author'].isin(selected_authors_1)].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf17fcf7-879a-4053-8eca-84468af70fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>vitae</td>\n",
       "      <td>vita_columbani</td>\n",
       "      <td>dominus eximius sacer culmen regimen decoratis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>bonifatius</td>\n",
       "      <td>bonifatius_enigmata</td>\n",
       "      <td>enigmata p aureus decem transmitto pomum soror...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>sedulius</td>\n",
       "      <td>sedulius4</td>\n",
       "      <td>sedulius carmen paschal sedulius carmen pascha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>sedulius</td>\n",
       "      <td>sedulius5</td>\n",
       "      <td>sedulius carmen paschal sedulius carmen pascha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>sedulius</td>\n",
       "      <td>sedulius1</td>\n",
       "      <td>sedulius carmen paschal sedulius carmen pascha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.dialogus</td>\n",
       "      <td>saepe requiro justus fabi prior saeculum tot e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann15</td>\n",
       "      <td>interea rex parthi uologaeses cognosco corbulo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann11</td>\n",
       "      <td>ualerium asiaticum bis consul quondam adulter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann12</td>\n",
       "      <td>caedes messalinae convulsus princeps domus ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "      <td>tacitus</td>\n",
       "      <td>tac.ann13</td>\n",
       "      <td>primus nouus principatus mors iunii silanus pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target      author                title  \\\n",
       "22        1       vitae       vita_columbani   \n",
       "25        1  bonifatius  bonifatius_enigmata   \n",
       "69        1    sedulius            sedulius4   \n",
       "70        1    sedulius            sedulius5   \n",
       "71        1    sedulius            sedulius1   \n",
       "..      ...         ...                  ...   \n",
       "892       0     tacitus         tac.dialogus   \n",
       "893       0     tacitus            tac.ann15   \n",
       "894       0     tacitus            tac.ann11   \n",
       "895       0     tacitus            tac.ann12   \n",
       "896       0     tacitus            tac.ann13   \n",
       "\n",
       "                                                  text  \n",
       "22   dominus eximius sacer culmen regimen decoratis...  \n",
       "25   enigmata p aureus decem transmitto pomum soror...  \n",
       "69   sedulius carmen paschal sedulius carmen pascha...  \n",
       "70   sedulius carmen paschal sedulius carmen pascha...  \n",
       "71   sedulius carmen paschal sedulius carmen pascha...  \n",
       "..                                                 ...  \n",
       "892  saepe requiro justus fabi prior saeculum tot e...  \n",
       "893  interea rex parthi uologaeses cognosco corbulo...  \n",
       "894  ualerium asiaticum bis consul quondam adulter ...  \n",
       "895  caedes messalinae convulsus princeps domus ori...  \n",
       "896  primus nouus principatus mors iunii silanus pr...  \n",
       "\n",
       "[140 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = df[df['author'].isin(selected_authors_0 + selected_authors_1)]\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b78bf20-bc43-4850-bbfa-d5c9effec000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>prudentius</td>\n",
       "      <td>prud.psycho</td>\n",
       "      <td>praefatio senex fidelis primus credo uia abram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius3</td>\n",
       "      <td>epistula sidonius auitus salus multus uinculum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius2</td>\n",
       "      <td>epistula sidonius ecdicio salus duo nunc parit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius1</td>\n",
       "      <td>epistula sidonius constantio salus praecipio d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>sidonius</td>\n",
       "      <td>sidonius5</td>\n",
       "      <td>epistula sidonius petronius salus audio lectit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>0</td>\n",
       "      <td>cicero</td>\n",
       "      <td>fam3</td>\n",
       "      <td>scr roma exeo cicero adpio imp senatus res pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>0</td>\n",
       "      <td>cicero</td>\n",
       "      <td>domo</td>\n",
       "      <td>multus divinitus pontifex magnus noster inueni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0</td>\n",
       "      <td>cicero</td>\n",
       "      <td>nd2</td>\n",
       "      <td>cotta dico uelleius inquam incautus academicus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0</td>\n",
       "      <td>cicero</td>\n",
       "      <td>fam14</td>\n",
       "      <td>scr dyrrhachii kal decembres tullius terentiae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0</td>\n",
       "      <td>ammianus</td>\n",
       "      <td>ammianus_res_gestae</td>\n",
       "      <td>liber caput gallus caesar saeuitia emetior ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>758 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target      author                title  \\\n",
       "0         1  prudentius          prud.psycho   \n",
       "1         1    sidonius            sidonius3   \n",
       "2         1    sidonius            sidonius2   \n",
       "3         1    sidonius            sidonius1   \n",
       "4         1    sidonius            sidonius5   \n",
       "..      ...         ...                  ...   \n",
       "827       0      cicero                 fam3   \n",
       "828       0      cicero                 domo   \n",
       "829       0      cicero                  nd2   \n",
       "830       0      cicero                fam14   \n",
       "897       0    ammianus  ammianus_res_gestae   \n",
       "\n",
       "                                                  text  \n",
       "0    praefatio senex fidelis primus credo uia abram...  \n",
       "1    epistula sidonius auitus salus multus uinculum...  \n",
       "2    epistula sidonius ecdicio salus duo nunc parit...  \n",
       "3    epistula sidonius constantio salus praecipio d...  \n",
       "4    epistula sidonius petronius salus audio lectit...  \n",
       "..                                                 ...  \n",
       "827  scr roma exeo cicero adpio imp senatus res pub...  \n",
       "828  multus divinitus pontifex magnus noster inueni...  \n",
       "829  cotta dico uelleius inquam incautus academicus...  \n",
       "830  scr dyrrhachii kal decembres tullius terentiae...  \n",
       "897  liber caput gallus caesar saeuitia emetior ins...  \n",
       "\n",
       "[758 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = df[~df['author'].isin(selected_authors_0 + selected_authors_1)]\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43d0ccac-6d13-4275-8f68-41d8d8c8c0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    659\n",
       "1     99\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30a92bb0-d291-4caf-8844-db75c861c43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    99\n",
       "1    99\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([train_df[train_df.target == 0].sample(99), train_df[train_df.target == 1]], ignore_index = True)\n",
    "df_balanced.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d73cd655-1780-4cbd-82e9-e774dff759e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1595a3-40d2-475c-860a-6f30d153edfe",
   "metadata": {},
   "source": [
    "**Оценка моделей**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc268ed8-c158-4c64-bd45-fa740aab5c69",
   "metadata": {},
   "source": [
    "Начнем по порядку оценивать качество моделей, варьируя гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9f5e2b7-2caf-4b67-b5e8-e9a55d4aa6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "073a5825-f2d6-4176-89d7-f7783324a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 500, max ngram: 1, accuracy: 0.4863473672297202\n",
      "Vocabulary size: 500, max ngram: 2, accuracy: 0.48541366041366046\n",
      "Vocabulary size: 500, max ngram: 3, accuracy: 0.48541366041366046\n",
      "Vocabulary size: 500, max ngram: 4, accuracy: 0.48541366041366046\n",
      "Vocabulary size: 1000, max ngram: 1, accuracy: 0.4805272614096143\n",
      "Vocabulary size: 1000, max ngram: 2, accuracy: 0.4805272614096143\n",
      "Vocabulary size: 1000, max ngram: 3, accuracy: 0.4805272614096143\n",
      "Vocabulary size: 1000, max ngram: 4, accuracy: 0.4805272614096143\n",
      "Vocabulary size: 5000, max ngram: 1, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 5000, max ngram: 2, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 5000, max ngram: 3, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 5000, max ngram: 4, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 10000, max ngram: 1, accuracy: 0.5894919078742608\n",
      "Vocabulary size: 10000, max ngram: 2, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 10000, max ngram: 3, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 10000, max ngram: 4, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 20000, max ngram: 1, accuracy: 0.5756030189853719\n",
      "Vocabulary size: 20000, max ngram: 2, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 20000, max ngram: 3, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 20000, max ngram: 4, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 30000, max ngram: 1, accuracy: 0.5894919078742608\n",
      "Vocabulary size: 30000, max ngram: 2, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 30000, max ngram: 3, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 30000, max ngram: 4, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 50000, max ngram: 1, accuracy: 0.5756030189853719\n",
      "Vocabulary size: 50000, max ngram: 2, accuracy: 0.571634765017118\n",
      "Vocabulary size: 50000, max ngram: 3, accuracy: 0.571634765017118\n",
      "Vocabulary size: 50000, max ngram: 4, accuracy: 0.571634765017118\n",
      "Vocabulary size: 100000, max ngram: 1, accuracy: 0.5774548708372238\n",
      "Vocabulary size: 100000, max ngram: 2, accuracy: 0.5774548708372238\n",
      "Vocabulary size: 100000, max ngram: 3, accuracy: 0.5855236539060068\n",
      "Vocabulary size: 100000, max ngram: 4, accuracy: 0.571634765017118\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "logreg_list = []\n",
    "\n",
    "for vocab in vocab_dim:\n",
    "    for n in ngram:\n",
    "        \n",
    "        tfidf = TfidfVectorizer(max_features=vocab, ngram_range=(1, n))\n",
    "        \n",
    "        X = tfidf.fit_transform(df_balanced['text']).toarray()\n",
    "        y = np.asarray(df_balanced['target'])\n",
    "        \n",
    "        model.fit(X, y)\n",
    "        accuracy = compute_accuracy(tfidf, model, test_df)\n",
    "        print(f\"Vocabulary size: {vocab}, max ngram: {n}, accuracy: {accuracy}\")\n",
    "        logreg_list.append((vocab, n, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2568c8f8-40a3-453a-a656-f7cc40b3c293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8506a3b0-b825-46d2-85b4-02bef9d7ecf2",
   "metadata": {},
   "source": [
    "Наилучшая точность 0.589 получена при размере словаря 10000 и 30000 и размере n-грамм 1. Тем не менее, качеcтво результатов нельзя считать удовлетворительным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbcdc3b5-f707-41a3-a9f7-26e9791a7ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 500, max ngram: 1, accuracy: 0.4942177376000905\n",
      "Vocabulary size: 500, max ngram: 2, accuracy: 0.4893157768157768\n",
      "Vocabulary size: 500, max ngram: 3, accuracy: 0.4893157768157768\n",
      "Vocabulary size: 500, max ngram: 4, accuracy: 0.4893157768157768\n",
      "Vocabulary size: 1000, max ngram: 1, accuracy: 0.500699219081572\n",
      "Vocabulary size: 1000, max ngram: 2, accuracy: 0.500699219081572\n",
      "Vocabulary size: 1000, max ngram: 3, accuracy: 0.500699219081572\n",
      "Vocabulary size: 1000, max ngram: 4, accuracy: 0.500699219081572\n",
      "Vocabulary size: 5000, max ngram: 1, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 5000, max ngram: 2, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 5000, max ngram: 3, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 5000, max ngram: 4, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 10000, max ngram: 1, accuracy: 0.583671802054155\n",
      "Vocabulary size: 10000, max ngram: 2, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 10000, max ngram: 3, accuracy: 0.5045051353874883\n",
      "Vocabulary size: 10000, max ngram: 4, accuracy: 0.5045051353874883\n",
      "Vocabulary size: 20000, max ngram: 1, accuracy: 0.583671802054155\n",
      "Vocabulary size: 20000, max ngram: 2, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 20000, max ngram: 3, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 20000, max ngram: 4, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 30000, max ngram: 1, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 30000, max ngram: 2, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 30000, max ngram: 3, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 30000, max ngram: 4, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 50000, max ngram: 1, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 50000, max ngram: 2, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 50000, max ngram: 3, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 50000, max ngram: 4, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 100000, max ngram: 1, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 100000, max ngram: 2, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 100000, max ngram: 3, accuracy: 0.5003384687208217\n",
      "Vocabulary size: 100000, max ngram: 4, accuracy: 0.5003384687208217\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVC()\n",
    "svm_list = []\n",
    "\n",
    "for vocab in vocab_dim:\n",
    "    for n in ngram:\n",
    "        \n",
    "        tfidf = TfidfVectorizer(max_features=vocab, ngram_range=(1, n))\n",
    "        \n",
    "        X = tfidf.fit_transform(df_balanced['text']).toarray()\n",
    "        y = np.asarray(df_balanced['target'])\n",
    "        \n",
    "        model.fit(X, y)\n",
    "        accuracy = compute_accuracy(tfidf, model, test_df)\n",
    "        print(f\"Vocabulary size: {vocab}, max ngram: {n}, accuracy: {accuracy}\")\n",
    "        svm_list.append((vocab, n, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe291f-1183-47e9-846d-5a81e0414c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f863021a-9b46-4757-978c-615d0b75c83b",
   "metadata": {},
   "source": [
    "И снова наилучший результат 0.584 достигается при размере словаря 10000 и размерен n-грамм 1.\n",
    "На всякий случай проверим еще один алгоритм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7674a52-ab58-4939-8225-f6eb37ba4a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 500, max ngram: 1, accuracy: 0.4829984013807543\n",
      "Vocabulary size: 500, max ngram: 2, accuracy: 0.5415595025889144\n",
      "Vocabulary size: 500, max ngram: 3, accuracy: 0.48993506493506495\n",
      "Vocabulary size: 500, max ngram: 4, accuracy: 0.504368616133322\n",
      "Vocabulary size: 1000, max ngram: 1, accuracy: 0.5244521545992135\n",
      "Vocabulary size: 1000, max ngram: 2, accuracy: 0.49867901706137\n",
      "Vocabulary size: 1000, max ngram: 3, accuracy: 0.4648406332229862\n",
      "Vocabulary size: 1000, max ngram: 4, accuracy: 0.5064531873355403\n",
      "Vocabulary size: 5000, max ngram: 1, accuracy: 0.49162139603316074\n",
      "Vocabulary size: 5000, max ngram: 2, accuracy: 0.5059559177206235\n",
      "Vocabulary size: 5000, max ngram: 3, accuracy: 0.4840944458591518\n",
      "Vocabulary size: 5000, max ngram: 4, accuracy: 0.5677722604193193\n",
      "Vocabulary size: 10000, max ngram: 1, accuracy: 0.4761278753925813\n",
      "Vocabulary size: 10000, max ngram: 2, accuracy: 0.4564411623235152\n",
      "Vocabulary size: 10000, max ngram: 3, accuracy: 0.4668042469513058\n",
      "Vocabulary size: 10000, max ngram: 4, accuracy: 0.4854833347480407\n",
      "Vocabulary size: 20000, max ngram: 1, accuracy: 0.6086092012562601\n",
      "Vocabulary size: 20000, max ngram: 2, accuracy: 0.47040396966867554\n",
      "Vocabulary size: 20000, max ngram: 3, accuracy: 0.374202105084458\n",
      "Vocabulary size: 20000, max ngram: 4, accuracy: 0.5667002659649718\n",
      "Vocabulary size: 30000, max ngram: 1, accuracy: 0.5156480774127833\n",
      "Vocabulary size: 30000, max ngram: 2, accuracy: 0.43919481934187815\n",
      "Vocabulary size: 30000, max ngram: 3, accuracy: 0.4672251223721812\n",
      "Vocabulary size: 30000, max ngram: 4, accuracy: 0.5782520583991172\n",
      "Vocabulary size: 50000, max ngram: 1, accuracy: 0.45876305067481543\n",
      "Vocabulary size: 50000, max ngram: 2, accuracy: 0.3720556404379934\n",
      "Vocabulary size: 50000, max ngram: 3, accuracy: 0.5306192173839233\n",
      "Vocabulary size: 50000, max ngram: 4, accuracy: 0.3921855105678635\n",
      "Vocabulary size: 100000, max ngram: 1, accuracy: 0.4095874713521772\n",
      "Vocabulary size: 100000, max ngram: 2, accuracy: 0.47172848937554823\n",
      "Vocabulary size: 100000, max ngram: 3, accuracy: 0.5421855105678636\n",
      "Vocabulary size: 100000, max ngram: 4, accuracy: 0.4860262286732875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "forest_list = []\n",
    "\n",
    "for vocab in vocab_dim:\n",
    "    for n in ngram:\n",
    "        \n",
    "        tfidf = TfidfVectorizer(max_features=vocab, ngram_range=(1, n))\n",
    "        \n",
    "        X = tfidf.fit_transform(df_balanced['text']).toarray()\n",
    "        y = np.asarray(df_balanced['target'])\n",
    "        \n",
    "        model.fit(X, y)\n",
    "        accuracy = compute_accuracy(tfidf, model, test_df)\n",
    "        print(f\"Vocabulary size: {vocab}, max ngram: {n}, accuracy: {accuracy}\")\n",
    "        forest_list.append((vocab, n, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7fa24e-a96a-475a-92ed-f6fa09c7c815",
   "metadata": {},
   "source": [
    "Наилучшая точность 0.61 достигается при размере словаря 20000 и размере n-грамм 1.\n",
    "\n",
    "Можно сделать такой вывод: либо разбиение на train и test было неудачным, либо модели на мешке слов не подходят для нашей задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70456209-1ace-4513-b2a5-72a5efd88443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
